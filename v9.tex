\section{Vorlesung 9 \href{https://tu-dresden.de/mn/math/algebra/das-institut/beschaeftigte/antje-noack/ressourcen/dateien/v120-1/MathMethInf09.pdf?lang=en}{(14.05.2019)} }

\begin{definition}[Taylorscher Satz]
Sei $f : [a,b] \rightarrow \mathbb{R} $ eine $C^n$ - Funktion , $ n \in \mathbb{N}$ und $x_0 \in ]a , b[$.\\
Dann gibt es genau ein Polynom $T_n(x;x_0)$ höchstens n-ten Grades mit Approximationsgüte 
 \[ f(x) = T_n(x;x_0) + o((x-x_0)^n), \]
das so genannte \textbf{Taylor Polynom n-ten Gerades} zum Entwicklungspunkt $x_0$
\[ T_n(x;x_0) := \sum_{k=0}^{n}{\dfrac{f^(k)(x_0)}{k!}(x-x_0)^k} \]
Ist $ f $ eine $C^{(n+1)}$- Funktion, so gilt für den Fehler die so genannte \textbf{Restgliedformel nach Lagrange}
\[ f(x) = \sum_{k=0}^{n}{\dfrac{f^(k)(x_0)}{k!}(x-x_0)^k} + R_n(x;x_0), \quad a \leq x \leq b \]    

\end{definition}



\begin{example}
$f: \mathbb{R} \rightarrow \mathbb{R} : x \mapsto x^2-1 $ gesucht
\end{example}
\subsection{Taylor-Polynom $P_n(x)$ von $f(x)$}
\begin{center}
\begin{tabular}{ c c c }
$f(x)= x^2-1$  & $f(0) = 1 $     & $f(1) = 0$ \\ 
$f'(x) = 2x $  & $f'(0) = 0 $    & $f'(1) = 2$ \\  
$f''(x) = 2 $  & $f''(0) = 2 $   & $f''(1) = 2$  \\
$f'''(x) = 0 $ & $f'''(0) = 0 $  & $f'''(1) = 0$  
\end{tabular}
\end{center}

\begin{align*}
p_n(x) &= \underbrace{f(0) + f'(0)(x-0)}_{t(x) \text{ lineare Approximation }}  + \frac{f''(0)}{2!}(x-0)^2 + \frac{f'''(0)}{3!}(x-0)^3 + \dots\\
&= -1 + 0 x + \frac{2}{2!} x^2 + 0 = -1 + x^2 = f(x)
\end{align*}
Das Polynom ist bei der Entwicklung zu einem Taylor-Polynom zum selben Polynom zurückgekommen

\begin{align*}
p_n(x)&= f(1) + f'(1)(x-1)+ \dots \\
&= 0 + 2(x-1) + \frac{2}{2!}(x-1)^2 + 0 \\
&= 2x -2 + x^2 -2x +1 = x^2 -1
\end{align*} 

\begin{example}
gegeben : $f(x) = \frac{e^x}{cos(x)}$  gesucht : $p_2(x)$ für $x_0=0$\\
Methode des Impliziten Differenzieren 
\begin{gather*}
f(x) cos(x) + f(x)(-sin(x)) = e^x \quad | \quad \text{abl.} \\
f'(x) cos(x) + f(x)(-sin(x))= e^x \quad | \quad \text{abl.} \\
f''(x)cos(x) + f'(x)(-sin(x))+ f'-(x)(-sin(x)) + f(x)(- cos(x)) = e^x \\
f(0)cos(0) = e^0 \Rightarrow f(0) = 1\\
f'(0)\times 1 + f(0) \times 0 = 1 \Rightarrow f'(0) = 1\\
f''(0)\times 1 + f(0) \times (-1) = 1 \Rightarrow f''(0) = 2\\
p_2(x) = 1 + 1 x + \frac{2}{2!}x^2 = 1 + x + x^2\\
f(x) = \frac{1}{x+1}
\end{gather*}
\end{example}

\begin{example}
$f^k(x) = (-1)^k \frac{k!}{(1+x)^{k+1}}$\\
$\textbf{Induktionsanfang}$ 
\[ f^0(x) = f(x) = \frac{1}{1+x} = (-1)^0 \frac{0!}{(x+1)^{0+1}} = 1 \frac{1}{x+1} = \frac{1}{x+1} \text{w.A}\]
$\textbf{Induktionsschritt}$\\
$\textbf{Induktionsvoraussetzung}$\\
Es gelte $f^k(x)=(-1)^k\frac{k!}{(x +1)^{k+^1}}$ für $k \in \mathbb{N}$\\
$\textbf{Induktionsbehauptung}$ : Dann gilt \\
\[ f^{(k+1)}(x)= (-1)^{(k+1)} \frac{(k+1)!}{(x+1)^{(k+2)}}\]
\textbf{Induktionsbeweis}\\
$(\dots \dots)$\\
\begin{align*}
f^{(f+1)}(x) = (f^x(x))' &= \big((-1)^k \frac{k!}{(x+1)^{(k+1)}}\big )' \\
&= (-1)^k k! (x+1)^{-(k+1)}\\
&= (-1)^k k! (-(k+1)(x+1))^{-(k+^2)}\\
&= (-1)^{k+1} (k+1)! \frac{1}{(x+1)^{t+2}} \Rightarrow \text{ Ind Beh . ist dann bewiesen. }\\
\text{Die behauptung gilt für alle } k \in \mathbb{N}
\end{align*}
\end{example}
\begin{example}
$f(x)= \frac{1}{1+x}$ 
\[ p_1(x) = 1-x \]
\[ p_2(x) = 1-x + x^2 \]
\[ p_3(x) = 1-x+x^2+x^3 \]
\end{example}
\begin{remark}
Bei : $p_2(x)$ wird der Fehler für große werte von x größer der Fehler bei $p_1(x) , p_2(x)$
\end{remark}
\subsection{Taylor-Formel:}
\[ F(x) = p_n(x)+ \underbrace{R_n(x,x_0)}_{=  \text{n-tes Restglied }} R_n(x,x_0) \text{Fehler bei der Approximation.} \]
\begin{theorem}
Darstellung von $R_n(x,x_0)$ nach Lagrange 
Sei $f:(a,b) \rightarrow \mathbb{R}$ eine $(n+1)$ und stetig differenzierbar Funktion und $x_0 \in (a,b)$
Dann gilt : $f(x)= p_n(x)+ R_n(x_1 , x_0)$ und $\forall x \in (a,b) \exists z \in \mathbb{R}$ zwischen $x$ und $x_0$ : \\
   \[ R_n(x , x_0) = \frac{f^{(n+1)}(z)}{(n+1)!}(x-x_0)^{(n+1)}) \]
\end{theorem}
\begin{example}
$f(x)=e^x$ , $x = 0$
\begin{gather*}
f^k(x)= e^x\\
f^k(0)= 1 \Rightarrow P_n(x) = \sum_{k=0}^{n}{\frac{p^k(0)}{k!}x^k} = \sum_{k=0}^{n}{\frac{x^k}{k!}}\\
f(x)= p_n(x) + R_n(x,0) \text{ und } R_n(x,0) = \frac{e^z}{(n+1)!} y^{n+1} \quad z \in (x,0)\\
\text{wir betrachten } f(x) = e^x \text{ für } |x| \leq 1\\
\big|R_n(x,0)|=|\frac{e^z}{(n+1)!}x^{n+1}| \leq \frac{e^1}{(n+1)!} \leq 10^{-2} \text{ für } n = 5
\end{gather*}
\subsection{Näherungsformel für $e^x$}
\[ p_5 (x) = 1 + x + \frac{x^2}{2} + \frac{x^3}{3!} + \frac{x^4}{4!} + \frac{x^5}{5!} \text{ für } x \leq 1 \]
\end{example}
\begin{definition}
Sei $f : (a,b) \rightarrow \mathbb{R}$ beliebig oft stetig differenzierbar und $x_0 \in (a,b)$\\
Die Reihe \[ \sum_{k=0}^{\infty}{\frac{f^k(x_0)}{k!}(x-x_0)^k}\] heißt \textbf{Taylor Reihe} von $f$ an der stelle $x_0$ 
\end{definition}
\begin{remark}
(1) Nicht für jede Funktion $f(x)$ ist dir \textbf{Taylor-Reihe konvergent}\\
(2) Ist die Taylor-Reihe konvergent , dann muss der Grenzwert ......... die Funktion $f$ sein.\\
(3) Ist die Taylor-reihe konvergent gegen $f$ , d.h \[f(x)= \sum_{k=0}^{\infty}{\frac{f^k(x_0)}{k!}(x - x_0)^k}\] , heißt die Funktion $f$ \textbf{reell analytisch} \\
\end{remark}
\begin{example}
\[ f(x) = \frac{1}{x+1} \text{ mit } x \in (-1 , 1) \text{ ist reell analytisch }  \]
Taylor-reihe $\sum_{k=0}^{\infty}{(-1)^kx^k}$ hat konvergenzradius 1(...) und Mittelpunkt 0 
\end{example}
\begin{theorem}
Sei $|x| \leq 1 $ Dann gilt: $f(x) = \frac{1}{1 + x} =\frac{1}{1-(-x)} = \sum_{k=0}^{\infty}{x^k} = \sum_{k=0}^{\infty}{(-1)^kx^k}$ ist die Taylor-reihe Darstellung von $f(x)$ 
\end{theorem}
\subsection{Rechnen mit Potenzreihen: }
\textbf{\href{https://tu-dresden.de/mn/math/algebra/das-institut/beschaeftigte/antje-noack/ressourcen/dateien/v120-1/MathMethInf09Zusatz.pdf?lang=en}{Sieh der Zusatz (Rechnen mit Potenzreihen)}}\\
Es Sei \[ \sum_{k=0}^{\infty}{a_k(x - x_0)^k} := a(x) , b(x) =\sum_{k=0}^{\infty}{b_k(x-x_0)^k}\]
mit konvergenzradius $r_1$  für $a(x)$ , $r_2$ für b(x) sei r := min \{$r_1$ , $r_2$ \}\\
Dann gilt :
\begin{align*}
a(x) \pm b(x)&= \sum_{k=0}^{\infty}{(a_k + b_k)(x - x_0)^k}  \text{ für } x \in (x_0 - r , x_0 + r) \\
 C \times a(x) &= \sum_{k=0}^{\infty}{c.a_k(x-x_0)^k} \text{ für } x \in (x_0 -r , x_0+r) c \in \mathbb{R}\\
 a(x) . b(x) &= \sum_{k=0}^{\infty}{(a_0 b_k + a_1 b_{k-1}+ \dot + \dots +a_kb_0)(x- x_0)^k}
\end{align*}
$\dfrac{1}{b(x)}$  für  $b(x) \neq 0$  kann mit der Methode unbestimmten Koeffizienten. 